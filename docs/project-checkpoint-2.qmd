---
format:
  revealjs:
    width: 1600
    height: 900
    scrollable: true
---

## Slide 1 - Problem statement & goal

**Problem:** Generic pollen forecasts ignore individual sensitivity and history, producing poor, non-actionable guidance for many allergy sufferers.

**Primary goal:** Build a prototype that fuses local pollen & weather data to produce **daily symptom severity forecasts** and identify likely allergen drivers (actionable alerts).

---

## Slide 2 - Methodology overview

**Data inputs**  
- **Pollen counts:** Daily total pollen counts (target converted to 0–10 severity scale based on dataset percentiles)  
- **Temporal features:** Year, month, day-of-year, day-of-week + cyclical encodings (sine/cosine)  
- **Weather features:** Daily max/min temperature, precipitation, wind speed, derived temperature range, rainy-day indicator, high-wind indicator  
- **Lagged signals:** 1-, 3-, and 7-day lags for pollen, temperature, precipitation  
- **Rolling averages:** 3-, 7-, and 14-day rolling means for pollen counts  

**Model**  
- **Random Forest Regressor** trained to predict daily pollen severity (0–10 scale)  
- **Evaluation metrics (so far):** MAE, RMSE, R² on held-out test set  

---

## Slide 3 - Code snippet 1

```python
# create lag + rolling features (example)
def make_lag_rolling_features(df, cols, lags=(1,2,3), window=7):
    for c in cols:
        for lag in lags:
            df[f"{c}_lag{lag}"] = df[c].shift(lag)
        df[f"{c}_roll_mean{window}"] = df[c].rolling(window=window, min_periods=1).mean()
        df[f"{c}_roll_std{window}"] = df[c].rolling(window=window, min_periods=1).std().fillna(0)
    # basic imputation for edges
    return df.fillna(method="bfill").fillna(0)
```

---

## Slide 4 - Explanation of snippet 1

- This function synthesizes temporal signals that are shown to matter for symptom forecasting:
  - **Lag features** capture short-term persistence (yesterday's pollen often predicts today).
  - **Rolling mean/std** capture local trends and volatility (e.g., a multi-day pollen spike).
- These features are lightweight, fast to compute, and were used in the current model run.

---

## Slide 5 - Code snippet 2

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
import joblib

rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)
scores = cross_val_score(rf, X_train, y_train, cv=5, scoring="neg_mean_absolute_error")
rf.fit(X_train, y_train)
joblib.dump(rf, "models/pollen_rf_v1.joblib")
print("CV MAE:", -scores.mean())
```

---

## Slide 6 - Explanation of snippet 2

- **Model choice:** Random Forest regression - good bias/variance tradeoff for tabular time-series features, quick to train for iterations.
- **Cross-validation:** 5-fold CV using negative MAE for an initial estimate of generalization.
- **Persistence:** model serialized via `joblib` for the demo and integration into the prototype app.  

---

## Slide 7 - Preliminary results
 
- **Test MAE ≈ 0.72** - *average prediction error < 1 severity level.*  
  - **Interpretation:** The model’s predictions are typically within one severity category of the true value, which is considered **Excellent** per our rubric (MAE ≤ 1.0).
- **Test RMSE ≈ 0.98** - *slightly higher than MAE, indicating modest spread in errors.*  
  - **Interpretation:** Most errors are close to the mean; no major outlier problem.
- **Test R² ≈ 0.86** - *model explains ≈ 86% of the variance in daily pollen severity.*  
  - **Interpretation:** Strong fit - the model captures most of the signal from weather, temporal, and lag/rolling features.

---

## Slide 8 - Result Analysis & Next Steps

**Result analysis**  
- The current Random Forest baseline performs very well on predicting **daily pollen severity** (MAE ≈ 0.72, R² ≈ 0.86), meaning it is already reliably modeling seasonal and weather-driven pollen variation.  
- This confirms that the feature set (temporal, weather, lag/rolling) provides strong predictive signal and that the model is a solid foundation for personalization work.    

**Next steps**  
1. **Integrate symptom diary data** - collect or simulate daily symptom scores to train a per-user model.  
2. **Allergen identification module:** predict top-1 allergen driver; evaluate with Allergen F1 score.  
3. **High-risk classification:** define symptom threshold → alert days; compute high-risk F1 score.  